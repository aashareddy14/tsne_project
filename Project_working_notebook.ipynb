{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-0ff98941580f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecomposition\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPCA\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmath\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import scipy.linalg as la\n",
    "from keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix data\n",
    "X = np.array(iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "specs = np.array(iris['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset, which will serve as test dataset for building the algorithm\n",
    "#iris = datasets.load_iris()\n",
    "\n",
    "# Just to show the first 5 rows of iris dataset\n",
    "#df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "#df.head()\n",
    "#X = iris.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_euc_dist(X):\n",
    "    \"\"\"Calculate squared euclidean distance for all pairs in a data matrix X with d dimensions and n rows.\n",
    "    Output is a pairwise distance matrix D that is nxn.\n",
    "    \"\"\"\n",
    "    D = distance.squareform(distance.pdist(X, 'sqeuclidean'))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob_matrix(distances, sigmas):\n",
    "    \"\"\"Convert a distances matrix to a matrix of probabilities.\"\"\"\n",
    "    two_sig_sq = 2. * np.square(sigmas.reshape((-1, 1)))\n",
    "\n",
    "    X = distances / two_sig_sq\n",
    "\n",
    "    # Subtract max for numerical stability\n",
    "    e_x = np.exp(X - np.max(X, axis=1).reshape([-1, 1]))\n",
    "\n",
    "    # We usually want diagonal probailities to be 0.\n",
    "    np.fill_diagonal(e_x, 0.)\n",
    "\n",
    "    # Add a tiny constant for stability of log we take later\n",
    "    e_x += 1e-8  # numerical stability\n",
    "\n",
    "    return e_x / e_x.sum(axis=1).reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(eval_fn, target, tol=1e-10, max_iter=10000,\n",
    "                  lower=1e-20, upper=1000.):\n",
    "    \"\"\"Perform a binary search over input values to eval_fn.\n",
    "\n",
    "    # Arguments\n",
    "        eval_fn: Function that we are optimising over.\n",
    "        target: Target value we want the function to output.\n",
    "        tol: Float, once our guess is this close to target, stop.\n",
    "        max_iter: Integer, maximum num. iterations to search for.\n",
    "        lower: Float, lower bound of search range.\n",
    "        upper: Float, upper bound of search range.\n",
    "    # Returns:\n",
    "        Float, best input value to function found during search.\n",
    "    \"\"\"\n",
    "    for i in range(max_iter):\n",
    "        mid = (lower + upper) / 2.\n",
    "        val = eval_fn(mid)\n",
    "        if val > target:\n",
    "            upper = mid\n",
    "        else:\n",
    "            lower = mid\n",
    "        if np.abs(val - target) <= tol:\n",
    "            break\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(distances, sigmas):\n",
    "    \"\"\"calculate perplexity based on the P probability matrix.\"\"\"\n",
    "    prob_matrix = calc_prob_matrix(distances, sigmas)\n",
    "    entropy = -np.sum(prob_matrix * np.log2(prob_matrix), 1)\n",
    "    perplexity = 2 ** entropy\n",
    "\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def find_optimal_sigmas(distances, target_perplexity):\n",
    "    \"\"\"For each row of distances matrix, find sigma that results\n",
    "    in target perplexity for that role.\"\"\"\n",
    "    sigmas = []\n",
    "    # For each row of the matrix (each point in our dataset)\n",
    "    for i in range(distances.shape[0]):\n",
    "        # Make fn that returns perplexity of this row given sigma\n",
    "        eval_fn = lambda sigma: \\\n",
    "            perplexity(distances[i:i+1, :], np.array(sigma))\n",
    "        # Binary search over sigmas to achieve target perplexity\n",
    "        correct_sigma = binary_search(eval_fn, target_perplexity)\n",
    "        # Append the resulting sigma to our output array\n",
    "        sigmas.append(correct_sigma)\n",
    "    return np.array(sigmas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_tsne(Y):\n",
    "    \"\"\"t-SNE: Given low-dimensional representations Y, compute\n",
    "    matrix of joint probabilities with entries q_ij.\"\"\"\n",
    "    distances = -squared_euc_dist(Y)\n",
    "    inv_distances = np.power(1. - distances, -1)\n",
    "    np.fill_diagonal(inv_distances, 0.)\n",
    "    return inv_distances / np.sum(inv_distances), inv_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_joint(X, target_perplexity):\n",
    "    \"\"\"Given a data matrix X, gives joint probabilities matrix.\n",
    "\n",
    "    # Arguments\n",
    "        X: Input data matrix.\n",
    "    # Returns:\n",
    "        P: Matrix with entries p_ij = joint probabilities.\n",
    "    \"\"\"\n",
    "    # Get the negative euclidian distances matrix for our data\n",
    "    distances = -squared_euc_dist(X)\n",
    "    # Find optimal sigma for each row of this distances matrix\n",
    "    sigmas = find_optimal_sigmas(distances, target_perplexity)\n",
    "    # Calculate the probabilities based on these optimal sigmas\n",
    "    p_conditional = calc_prob_matrix(distances, sigmas)\n",
    "    # Go from conditional to joint probabilities matrix\n",
    "    P = (p_conditional + p_conditional.T) / (2. * p_conditional.shape[0])\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_grad(P, Q, Y):\n",
    "    \"\"\"Estimate the gradient of t-SNE cost with respect to Y.\"\"\"\n",
    "    pq_diff = P - Q\n",
    "    pq_expanded = np.expand_dims(pq_diff, 2)\n",
    "    y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)\n",
    "\n",
    "    # Get Q and distances (distances only used for t-SNE)\n",
    "    distances = q_tsne(Y)[1]\n",
    "\n",
    "    # Expand our inv_distances matrix so can multiply by y_diffs\n",
    "    distances_expanded = np.expand_dims(distances, 2)\n",
    "\n",
    "    # Multiply this by inverse distances matrix\n",
    "    y_diffs_wt = y_diffs * distances_expanded\n",
    "\n",
    "    # Multiply then sum over j's\n",
    "    grad = 4. * (pq_expanded * y_diffs_wt).sum(1)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sne(X, num_iters = 1000, q_fn = q_tsne, perplexity = 30, learning_rate = 10, momentum = 0.9):\n",
    "    \"\"\"Estimates a SNE model.\n",
    "\n",
    "    # Arguments\n",
    "        X: Input data matrix.\n",
    "        y: Class labels for that matrix.\n",
    "        P: Matrix of joint probabilities.\n",
    "        rng: np.random.RandomState().\n",
    "        num_iters: Iterations to train for.\n",
    "        q_fn: Function that takes Y and gives Q prob matrix.\n",
    "        plot: How many times to plot during training.\n",
    "    # Returns:\n",
    "        Y: Matrix, low-dimensional representation of X.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise our 2D representation, numpy RandomState for reproducibility\n",
    "    rng = np.random.RandomState(1)\n",
    "    Y = rng.normal(0., 0.0001, [X.shape[0], 2])\n",
    "\n",
    "    # Obtain matrix of joint probabilities p_ij\n",
    "    P = p_joint(X, perplexity)\n",
    "\n",
    "    # Initialise past values (used for momentum)\n",
    "    if momentum:\n",
    "        Y_m2 = Y.copy()\n",
    "        Y_m1 = Y.copy()\n",
    "\n",
    "    # Start gradient descent loop\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Get Q and distances (distances only used for t-SNE)\n",
    "        Q, distances = q_fn(Y)\n",
    "        # Estimate gradients with respect to Y\n",
    "        grads = tsne_grad(P, Q, Y)\n",
    "\n",
    "        # Update Y\n",
    "        Y = Y - learning_rate * grads\n",
    "        if momentum:  # Add momentum\n",
    "            Y += momentum * (Y_m1 - Y_m2)\n",
    "            # Update previous Y's for momentum\n",
    "            Y_m2 = Y_m1.copy()\n",
    "            Y_m1 = Y.copy()\n",
    "\n",
    "        # Plot sometimes\n",
    "        #if plot and i % (num_iters / plot) == 0:\n",
    "         #   categorical_scatter_2d(Y, y, alpha=1.0, ms=6,\n",
    "          #                         show=True, figsize=(9, 6))\n",
    "\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = estimate_sne(X)\n",
    "yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(yout[:,0], yout[:,1], hue = specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Mnist data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}